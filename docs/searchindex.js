Search.setIndex({"docnames": ["2022-06/paper-20220629", "2022-07/20220720_NeRF_original", "2022-08/20220828_BEIT", "2022-09/20220903_MAE", "2022-09/20220922_TTT-MAE", "2022-09/20220926_Diffusion_original", "2022-09/20220927_DDIB", "2022-09/20220928_zero-shot_text-to-image_gen", "index", "paper-template"], "filenames": ["2022-06\\paper-20220629.md", "2022-07\\20220720_NeRF_original.md", "2022-08\\20220828_BEIT.md", "2022-09\\20220903_MAE.md", "2022-09\\20220922_TTT-MAE.md", "2022-09\\20220926_Diffusion_original.md", "2022-09\\20220927_DDIB.md", "2022-09\\20220928_zero-shot_text-to-image_gen.md", "index.rst", "paper-template.md"], "titles": ["Weakly supervised individual ganglion cell segmentation from adaptive optics OCT images for glaucomatous damage assessment", "NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis", "BEIT: BERT Pre-Training of Image Transformers", "Maked Autoencoders Are Scalable Vision Learnears", "Test-Time Training with Masked Autoencoders", "Deep Unsupervised Learning using Nonequilibrium Thermodynamics", "Dual Diffusion Implicit Bridges for Image-to-Image Translation", "Zero-shot Text-to-Image Generation", "Welcome to paper-notes's documentation!", "Title"], "terms": {"reading": [0, 1, 2, 3, 4, 5, 6, 7, 9], "date": [0, 1, 2, 3, 4, 5, 6, 7, 9], "author": [0, 1, 2, 3, 4, 5, 6, 7, 9], "somayyeh": 0, "soltanian": 0, "-zadeh": 0, "sina": 0, "farsiu": 0, "affiliation": [0, 1, 2, 3, 4, 5, 6, 7, 9], "duke": 0, "univ": [0, 5], "duck": 0, "rating": [0, 1, 2, 3, 4, 5, 6, 7, 9], "\u2605\u2606": [0, 1, 4, 6, 7, 9], "\u2606\u2606": [0, 1, 6, 7, 9], "tag": [0, 1, 2, 3, 4, 5, 6, 7, 9], "\u7dd1\u5185\u969c": 0, "\u8a3a\u65ad": 0, "gc": 0, "\u9686\u8d77": 0, "\u8d77\u304d": 0, "\u672c\u5f53": 0, "\u7dd1\u5185": 0, "\u969c\u60a3": 0, "\u3042\u308b": [0, 4, 6], "\u534a\u5206": 0, "\u3050\u3089\u3044": [0, 2], "gcc": 0, "\u539a\u3055": 0, "\u6e2c\u308b": 0, "\u65b9\u6cd5": [0, 2], "\u63d0\u6848": [0, 2], "\u3044\u308b": [0, 2, 5], "\u7d30\u80de": 0, "\u8352\u3044": 0, "\u51dd\u96c6": 0, "\u3057\u304b": 0, "\u8a08\u6e2c": 0, "\u3067\u304d": [0, 5, 6], "\u306a\u3044": [0, 2], "\u306e\u3067": [0, 2], "\u30ec\u30d9\u30eb": 0, "\u30b5\u30a4\u30ba": 0, "\u5f62\u614b": 0, "\u5909\u5316": 0, "\u89b3\u5bdf": 0, "ao": 0, "-oct": 0, "\u306b\u3088\u308b": 0, "\u969c\u8a3a": 0, "\u554f\u984c": 0, "subjective": 0, "time": 0, "-consuming": 0, "not": [0, 3], "practical": 0, "large": 0, "-scale": 0, "studies": 0, "and": [0, 3, 4], "clinical": 0, "use": [0, 3], "transformer": [1, 2, 3, 4, 5, 6, 7, 9], "video": [1, 4, 5, 6], "prediction": [1, 4, 5, 6], "hangbo": 2, "bao": 2, "li": [2, 3], "dong": 2, "furu": 2, "wei": 2, "microsoft": 2, "research": [2, 3], "\u2605\u2605": [2, 3, 4, 5], "\u7528\u3044": 2, "\u3089\u308c": 2, "\u30c8\u30fc\u30af\u30f3": 2, "\u306b\u5bfe\u3057": [2, 4], "\u30de\u30b9\u30af": 2, "\u304b\u3051": 2, "\u305d\u306e": [2, 4], "\u90e8\u5206": 2, "\u63a8\u5b9a": 2, "\u305b\u308b": [2, 4], "\u3068\u3044\u3046": [2, 5], "\u5b66\u7fd2": [2, 4, 6], "\u624b\u6cd5": [2, 4], "vit": 2, "\u9069\u7528": [2, 6], "\u753b\u50cf": [2, 6], "\u30d4\u30af\u30bb\u30eb": 2, "\u307e\u307e": 2, "\u306a\u304f": [2, 4, 5], "tokennizer": 2, "\u306b\u3088\u3063": 2, "visual": 2, "tokens": 2, "\u4f5c\u6210": 2, "\u5bfe\u5fdc": 2, "\u3059\u308b": 2, "\u30d1\u30c3\u30c1": 2, "token": 2, "\u3088\u3046": 2, "\u6a5f\u69cb": 2, "ramesh": 2, "et": 2, "al": 2, ".,": 2, "\u76f4\u63a5": 2, "\u8fd1\u3044": 2, "\u8ddd\u96e2": 2, "\u4f9d\u5b58": 2, "\u95a2\u4fc2": 2, "\u9ad8\u3044": 2, "\u5468\u6ce2": 2, "\u7fd2\u5f97": 2, "\u826f\u3044": 2, "\u7d50\u679c": 2, "\u306a\u3089": 2, "\u3053\u3068": [2, 4, 5], "vae": 2, "tokenize": 2, "\u8a66\u3057": 2, "\u672c\u8ad6": 2, "\u7570\u306a\u308a": 2, "zero": 2, "shot": 2, "text": 2, "-to": [2, 8], "-image": [2, 8], "\u691c\u8a3c": 2, "\u4f7f\u308f": 2, "\u3082\u306e": 2, "\u5229\u7528": 2, "\u3054\u3068": 2, "\u5909\u63db": 2, "\u308c\u308b": 2, "\u3053\u306e": 2, "\u307e\u307e\u3067": 2, "\u975e\u9023": 2, "gumble": 2, "-softmax": 2, "relaxation": [], "\u4f7f\u3063": 2, "\u5fae\u5206": 2, "\u53ef\u80fd": 2, "backbone": 2, "network": 2, "(dosovitskiy": 2, "\u540c\u69d8": 2, "vaswani": 2, "\u6a19\u6e96": 2, "\u30c8\u30e9\u30f3\u30b9\u30d5\u30a9\u30fc\u30de\u30fc": 2, "\u4f7f\u7528": 2, "classifcation": [], "semantic": 2, "segmentation": [2, 8], "kaiming": 3, "he": 3, "xinlei": 3, "chen": [3, 4], "saining": 3, "xie": 3, "yanghao": 3, "piotr": 3, "doll": 3, "\u00e1r": 3, "ross": 3, "girshick": 3, "facebook": 3, "ai": 3, "self": 3, "-supervised": 3, "learning": [3, 8], "link": [3, 4, 5, 6, 7, 9], "this": 3, "paper": 3, "was": 3, "published": 3, "just": 3, "after": 3, "the": 3, "beit": [3, 8], "they": 3, "did": 3, "quite": 3, "similar": 3, "things": 3, "to": 3, "but": 3, "some": 3, "parts": 3, "different": 3, "which": 3, "leads": 3, "better": 3, "performances": 3, "on": 3, "imagenet": 3, "evalation": 3, "transfer": [3, 6], "experiments": 3, "main": 3, "two": 3, "differences": 3, "mae": 3, "does": 3, "any": 3, "tokenizer": 3, "masked": [3, 8], "patches": 3, "input": 3, "encoder": 3, "yossi": 4, "grandelsman": 4, "yu": 4, "sun": 4, "xiniei": 4, "alexei": 4, "efros": 4, ":uc": 4, "berkeley": [4, 5], "\u30c7\u30fc\u30bf": 4, "\u5206\u5e03": 4, "\u306a\u308b": 4, "\u3068\u304d": 4, "\u4e00\u304b\u3089": 4, "\u30e2\u30c7\u30eb": 4, "\u9069\u5fdc": 4, "\u4ee5\u4e0b\u7565": 4, "jascha": 5, "sohl": 5, "-dickstein": 5, "stanford": 5, "uc": 5, "\u30ce\u30a4\u30ba": 5, "\u639b\u3051": 5, "\u305d\u308c": 5, "\u623b\u3057": 5, "\u307e\u3067": 5, "\u7406\u89e3": [5, 6], "\u53b3\u5bc6": 5, "\u5f0f\u5468\u308a": 5, "\u3067\u3064\u3044": 5, "\u3044\u3051": 5, "\u306a\u3063": [2, 5], "maked": 8, "autoencoders": 8, "are": 8, "scalable": 8, "vision": 8, "learnears": 8, "test": 8, "-time": 8, "training": 8, "with": 8, "deep": 8, "unsupervised": 8, "using": 8, "nonequilibrium": 8, "thermodynamics": 8, "bert": 8, "pre": 8, "-training": 8, "of": 8, "image": 8, "transformers": 8, "nerf": 8, "representing": 8, "scenes": 8, "as": 8, "neural": 8, "radiance": 8, "fields": 8, "for": 8, "view": 8, "synthesis": 8, "weakly": 8, "supervised": 8, "individual": 8, "ganglion": 8, "cell": 8, "from": 8, "adaptive": 8, "optics": 8, "oct": 8, "images": 8, "glaucomatous": 8, "damage": 8, "assessment": 8, "\u7d22\u5f15": 8, "\u30e2\u30b8\u30e5\u30fc\u30eb": 8, "\u691c\u7d22": 8, "\u30da\u30fc\u30b8": 8, "##": [6, 7, 9], "\u4e8b\u524d": [2, 6], "\u4ee5\u4e0b": 2, "\u4e0b\u6d41": 2, "\u30bf\u30b9\u30af": 2, "\u6027\u80fd": 2, "\u8a55\u4fa1": 2, "classification": 2, "attention": 2, "\u898b\u3066": 2, "\u307f\u308b": 2, "\u30e9\u30d9\u30eb": 2, "\u4ed8\u4e0e": 2, "\u95a2\u308f\u3089": 2, "\u6ce8\u76ee": 2, "\u7269\u4f53": 2, "\u7279\u5fb4": 2, "\u3088\u304f": 2, "\u6349\u3048": 2, "\u660e\u3089\u304b": 2, "[1": 2, "\u30da\u30a2": 6, "\u4ee5\u5916": 6, "\u56f0\u96e3": 6, "\u30d7\u30e9\u30a4\u30d0\u30b7\u30fc": 6, "\u4fdd\u8b77": 6, "\u89b3\u70b9": 6, "\u6b20\u5982": 6, "\u4f8b\u3048": 6, "\u533b\u7642": 6, "style": 6, "\u304b\u3057\u3089": 6, "\u6570\u5f0f": 6, "\u96e3\u3057\u304f": 6, "orz": 6, "\u306a\u304b": 6, "\u96e3\u3057\u3044": 6, "\u3067\u3059": 6, "title": [], "dual": 8, "diffusion": 8, "implicit": 8, "bridges": 8, "translation": 8}, "objects": {}, "objtypes": {}, "objnames": {}, "titleterms": {"weakly": 0, "supervised": 0, "individual": 0, "ganglion": 0, "cell": 0, "segmentation": 0, "from": 0, "adaptive": 0, "optics": 0, "oct": 0, "images": 0, "for": [0, 1, 6], "glaucomatous": 0, "damage": 0, "assessment": 0, "\u8ad6\u6587": [0, 1, 2, 3, 4, 5, 6, 7, 9], "\u60c5\u5831": [0, 1, 2, 3, 4, 5, 6, 7, 9], "overview": [0, 1, 2, 3, 4, 5, 6, 7, 9], "\u3069\u3093\u306a": 0, "\u5148\u884c": [0, 1, 2, 4, 5, 6, 7, 9], "\u7814\u7a76": [0, 1, 2, 4, 5, 6, 7, 9], "\u6bd4\u8f03": [0, 1, 2, 4, 5, 7, 9], "key": [0, 1, 2, 4, 5, 6, 7, 9], "ideas": [0, 1, 2, 4, 5, 6, 7, 9], "evaluation": [0, 1, 2, 4, 5, 6, 7, 9], "method": [0, 1, 2, 4, 5, 6, 7, 9], "any": [0, 1, 2, 4, 5, 6, 7, 9], "discussion": [0, 1, 2, 4, 5, 6, 7, 9], "next": [0, 1, 2, 4, 5, 6, 7, 9], "papers": [0, 1, 2, 4, 5, 6, 7, 9], "to": [0, 1, 2, 4, 5, 6, 7, 8, 9], "read": [0, 1, 2, 4, 5, 6, 7, 9], "\u30e1\u30e2": [0, 1, 2, 4, 5, 6, 7, 9], "\u66f8\u304d": [0, 1, 2, 4, 5, 6, 7, 9], "introduction": [0, 1, 2, 4, 5, 6, 7, 9], "nerf": 1, "representing": 1, "scenes": 1, "as": 1, "neural": 1, "radiance": 1, "fields": 1, "view": 1, "synthesis": 1, "ee": [1, 4, 5, 6, 7, 9], "aaa": [1, 4, 5], "rere": [1, 4, 5], "beit": 2, "bert": 2, "pre": 2, "-training": 2, "of": 2, "image": [2, 6], "transformers": 2, "maked": 3, "autoencoders": [3, 4], "are": 3, "scalable": 3, "vision": 3, "learnears": 3, "test": 4, "-time": 4, "training": 4, "with": 4, "masked": 4, "deep": 5, "unsupervised": 5, "learning": 5, "using": 5, "nonequilibrium": 5, "thermodynamics": 5, "welcome": 8, "paper": 8, "-notes": 8, "'s": 8, "documentation": 8, "indices": 8, "and": 8, "tables": 8, "title": 9, "\u554f\u984c": 6, "dual": 6, "diffusion": 6, "implicit": 6, "bridges": 6, "-to": [6, 7], "-image": [6, 7], "translation": 6, "zero": 7, "-shot": 7, "text": 7, "generation": 7}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 8, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx": 57}, "alltitles": {"Weakly supervised individual ganglion cell segmentation from adaptive optics OCT images for glaucomatous damage assessment": [[0, "weakly-supervised-individual-ganglion-cell-segmentation-from-adaptive-optics-oct-images-for-glaucomatous-damage-assessment"]], "\u8ad6\u6587\u306e\u60c5\u5831": [[0, "id1"], [1, "id1"], [3, "id1"], [4, "id1"], [5, "id1"], [6, "id1"], [2, "id1"], [7, "id1"], [9, "id1"]], "Overview(\u3069\u3093\u306a\u8ad6\u6587)": [[0, "overview"]], "\u5148\u884c\u7814\u7a76\u3068\u306e\u6bd4\u8f03": [[0, "id2"], [1, "id2"], [4, "id2"], [5, "id2"], [2, "id2"], [7, "id2"], [9, "id2"]], "Key Ideas": [[0, "key-ideas"], [1, "key-ideas"], [4, "key-ideas"], [5, "key-ideas"], [6, "key-ideas"], [2, "key-ideas"], [7, "key-ideas"], [9, "key-ideas"]], "Evaluation method": [[0, "evaluation-method"], [1, "evaluation-method"], [4, "evaluation-method"], [5, "evaluation-method"], [6, "evaluation-method"], [2, "evaluation-method"], [7, "evaluation-method"], [9, "evaluation-method"]], "Any Discussion": [[0, "any-discussion"], [1, "any-discussion"], [4, "any-discussion"], [5, "any-discussion"], [6, "any-discussion"], [2, "any-discussion"], [7, "any-discussion"], [9, "any-discussion"]], "Next papers to read": [[0, "next-papers-to-read"], [1, "next-papers-to-read"], [4, "next-papers-to-read"], [5, "next-papers-to-read"], [6, "next-papers-to-read"], [2, "next-papers-to-read"], [7, "next-papers-to-read"], [9, "next-papers-to-read"]], "\u30e1\u30e2\u66f8\u304d": [[0, "id3"], [1, "id3"], [4, "id3"], [5, "id3"], [6, "id3"], [2, "id3"], [7, "id3"], [9, "id3"]], "Introduction": [[0, "introduction"], [1, "introduction"], [1, "id4"], [4, "introduction"], [4, "id4"], [5, "introduction"], [6, "introduction"], [6, "id4"], [2, "introduction"], [7, "introduction"], [7, "id4"], [9, "introduction"], [9, "id4"]], "NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis": [[1, "nerf-representing-scenes-as-neural-radiance-fields-for-view-synthesis"]], "Overview": [[1, "overview"], [3, "overview"], [4, "overview"], [5, "overview"], [6, "overview"], [2, "overview"], [7, "overview"], [9, "overview"]], "ee": [[1, "ee"], [4, "ee"], [5, "ee"], [6, "ee"], [7, "ee"], [9, "ee"]], "aaa": [[1, "aaa"], [4, "aaa"], [5, "aaa"]], "rere": [[1, "rere"], [4, "rere"], [5, "rere"]], "Maked Autoencoders Are Scalable Vision Learnears": [[3, "maked-autoencoders-are-scalable-vision-learnears"]], "Test-Time Training with Masked Autoencoders": [[4, "test-time-training-with-masked-autoencoders"]], "Deep Unsupervised Learning using Nonequilibrium Thermodynamics": [[5, "deep-unsupervised-learning-using-nonequilibrium-thermodynamics"]], "Welcome to paper-notes's documentation!": [[8, "welcome-to-paper-notes-s-documentation"]], "2022-09:": [[8, null]], "2022-08:": [[8, null]], "2022-07:": [[8, null]], "2022-06:": [[8, null]], "Indices and tables": [[8, "indices-and-tables"]], "Dual Diffusion Implicit Bridges for Image-to-Image Translation": [[6, "dual-diffusion-implicit-bridges-for-image-to-image-translation"]], "\u5148\u884c\u7814\u7a76\u306e\u554f\u984c\u70b9": [[6, "id2"]], "BEIT: BERT Pre-Training of Image Transformers": [[2, "beit-bert-pre-training-of-image-transformers"]], "Zero-shot Text-to-Image Generation": [[7, "zero-shot-text-to-image-generation"]], "Title": [[9, "title"]]}, "indexentries": {}})